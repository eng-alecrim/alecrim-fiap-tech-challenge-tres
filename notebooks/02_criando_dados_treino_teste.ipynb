{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotecas\n",
    "import pickle\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from src.utils import get_path_projeto\n",
    "\n",
    "# Diretórios\n",
    "dir_projeto = get_path_projeto()\n",
    "\n",
    "dir_staged = dir_projeto / \"data/staged\"\n",
    "dir_staged.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dir_models = dir_projeto / \"models\"\n",
    "dir_models.mkdir(exist_ok=True)\n",
    "\n",
    "# 1. Carregando os dados\n",
    "path_csv = dir_staged / \"dados_empilhados.csv\"\n",
    "config_csv = {\n",
    "    \"sep\": \"\\t\",\n",
    "    \"encoding\": \"utf-8\"\n",
    "}\n",
    "\n",
    "dataset = pd.read_csv(path_csv, **config_csv)\n",
    "\n",
    "# 2. Selecionando apenas dados sobre a geração de energia eólica\n",
    "wind_power_generation = dataset.loc[:, [\"interval_start_local\", \"wind\"]]\n",
    "wind_power_generation.rename(\n",
    "    columns={\"interval_start_local\": \"date\", \"wind\": \"power_generation\"},\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "# 3. Obtendo os valores da coluna de geração de energia\n",
    "wind_power_generation_values = wind_power_generation[\"power_generation\"].values\n",
    "\n",
    "\n",
    "# 4. Normalizando os dados\n",
    "scaler = MinMaxScaler()\n",
    "wind_power_generation_scaled_values = scaler.fit_transform(wind_power_generation_values.reshape(-1, 1)).ravel()\n",
    "\n",
    "# 5. Criando os dados de \"features\" e \"target\"\n",
    "window_len = 6  # Número de pontos que existem por meia hora\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(len(wind_power_generation_scaled_values) - window_len):\n",
    "    X.append(wind_power_generation_scaled_values[i:i + window_len])\n",
    "    y.append(wind_power_generation_scaled_values[i + window_len])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# 6. Dividindo os dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=42)\n",
    "\n",
    "# 7. Salvando para uso futuro\n",
    "\n",
    "# Scaler\n",
    "joblib.dump(scaler, dir_models / \"min_max_scaler.joblib\")\n",
    "\n",
    "# Dados de treino e teste\n",
    "train_test_data = {\n",
    "    \"X\": {\n",
    "        \"raw\": X,\n",
    "        \"train\": X_train,\n",
    "        \"test\": X_test\n",
    "    },\n",
    "    \"y\": {\n",
    "        \"raw\": y,\n",
    "        \"train\": y_train,\n",
    "        \"test\": y_test\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(dir_staged / \"train_test_data.pkl\", \"wb\") as pkl_f:\n",
    "    pickle.dump(obj=train_test_data, file=pkl_f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
